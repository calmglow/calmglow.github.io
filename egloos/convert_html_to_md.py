#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Egloos HTML to Markdown Converter
egloos ë¸”ë¡œê·¸ HTML íŒŒì¼ì„ Jekyll markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜
"""

import os
import re
import shutil
from pathlib import Path
from bs4 import BeautifulSoup
from datetime import datetime
import html


class EgloosConverter:
    def __init__(self, base_dir, output_dir, assets_dir):
        self.base_dir = Path(base_dir)
        self.output_dir = Path(output_dir)
        self.assets_dir = Path(assets_dir)
        self.error_log = []

    def convert_file(self, html_path):
        """ë‹¨ì¼ HTML íŒŒì¼ì„ Markdownìœ¼ë¡œ ë³€í™˜"""
        try:
            with open(html_path, 'r', encoding='utf-8') as f:
                content = f.read()

            soup = BeautifulSoup(content, 'html.parser')

            # 1. ì œëª© ì¶”ì¶œ
            title = self._extract_title(soup)
            if not title:
                raise ValueError("ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # 2. ë‚ ì§œ ì¶”ì¶œ
            date = self._extract_date(soup)
            if not date:
                raise ValueError("ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # 3. ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            category = self._extract_category(soup)
            categories = self._map_category(category)

            # 4. ë³¸ë¬¸ ì¶”ì¶œ
            post_content = self._extract_content(soup, html_path)

            # 5. Description ìƒì„± (ë³¸ë¬¸ ì²« 150ì)
            description = self._generate_description(post_content)

            # 6. ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì¶”ì¶œ (front matterìš©)
            first_image = self._extract_first_image(soup, html_path)

            # 7. ëŒ“ê¸€ ì¶”ì¶œ
            comments = self._extract_comments(soup)

            # 8. Markdown ìƒì„±
            markdown = self._generate_markdown(
                title, date, categories, description,
                first_image, post_content, comments
            )

            # 9. íŒŒì¼ ì €ì¥
            output_filename = self._generate_filename(date, title)
            output_path = self.output_dir / output_filename

            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(markdown)

            return output_path

        except Exception as e:
            error_msg = f"Error converting {html_path}: {str(e)}"
            self.error_log.append(error_msg)
            print(f"âŒ {error_msg}")
            return None

    def _extract_title(self, soup):
        """ì œëª© ì¶”ì¶œ"""
        title_elem = soup.find('h2', class_='entry-title')
        if title_elem:
            a_tag = title_elem.find('a')
            if a_tag:
                return a_tag.get('title', a_tag.get_text().strip())
        return None

    def _extract_date(self, soup):
        """ë‚ ì§œ ì¶”ì¶œ"""
        date_elem = soup.find('abbr', class_='published')
        if date_elem:
            date_str = date_elem.get('title', '')
            # "2011/09/27 09:16" í˜•ì‹
            try:
                return datetime.strptime(date_str, '%Y/%m/%d %H:%M')
            except:
                pass
        return None

    def _extract_category(self, soup):
        """ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
        cat_elem = soup.find('span', class_='post_title_category')
        if cat_elem:
            a_tag = cat_elem.find('a')
            if a_tag:
                return a_tag.get_text().strip()
        return None

    def _map_category(self, category):
        """ì¹´í…Œê³ ë¦¬ë¥¼ front matter ê°’ìœ¼ë¡œ ë§¤í•‘"""
        if category == "Art and Life":
            return "[life]"
        else:
            return "[tech]"

    def _extract_content(self, soup, html_path):
        """ë³¸ë¬¸ ì¶”ì¶œ ë° ì´ë¯¸ì§€ ì²˜ë¦¬"""
        content_elem = soup.find('div', class_='post_content entry-content')
        if not content_elem:
            return ""

        # hentry ë‚´ë¶€ì˜ ì‹¤ì œ ì½˜í…ì¸  ì°¾ê¸°
        hentry = content_elem.find('div', class_='hentry')
        if not hentry:
            return ""

        # ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±° (ì£¼ì„, RDF ë“±)
        from bs4 import Comment, NavigableString

        # HTML ì£¼ì„ ì œê±°
        for comment in hentry.find_all(string=lambda text: isinstance(text, Comment)):
            comment.extract()

        # RDF, script ë“± ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
        for tag in hentry.find_all(['script', 'iframe', 'style']):
            tag.decompose()

        # RDF íƒœê·¸ ì œê±° (namespace í¬í•¨)
        for tag in hentry.find_all():
            if tag.name and ('rdf' in tag.name.lower() or tag.name.startswith('rdf:')):
                tag.decompose()

        # ë¶ˆí•„ìš”í•œ span ë° ìˆ¨ê²¨ì§„ ìš”ì†Œ ì œê±°
        for tag in hentry.find_all('span', class_='copyright_entry'):
            tag.decompose()
        for tag in hentry.find_all(style=lambda value: value and 'display:none' in value):
            tag.decompose()
        for tag in hentry.find_all(style=lambda value: value and 'display: none' in value):
            tag.decompose()

        # ì´ë¯¸ì§€ ì²˜ë¦¬
        for img in hentry.find_all('img'):
            img_src = img.get('src', '')
            new_src = self._process_image(img_src, html_path)
            img['src'] = new_src

        # HTMLì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        content_text = self._html_to_markdown(hentry)

        return content_text.strip()

    def _process_image(self, img_src, html_path):
        """ì´ë¯¸ì§€ ê²½ë¡œ ì²˜ë¦¬ ë° íŒŒì¼ ë³µì‚¬"""
        # ì™¸ë¶€ URLì¸ ê²½ìš° (http://, https://)
        if img_src.startswith('http://') or img_src.startswith('https://'):
            return img_src

        # ìƒëŒ€ê²½ë¡œì¸ ê²½ìš°
        if img_src.startswith('../'):
            # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
            html_dir = Path(html_path).parent
            img_path = html_dir / img_src
            img_path = img_path.resolve()

            if img_path.exists():
                # íŒŒì¼ëª… ì¶”ì¶œ
                img_filename = img_path.name

                # assets ë””ë ‰í† ë¦¬ì— ë³µì‚¬
                dest_path = self.assets_dir / img_filename
                self.assets_dir.mkdir(parents=True, exist_ok=True)

                if not dest_path.exists():
                    shutil.copy2(img_path, dest_path)

                # Jekyll ê²½ë¡œ ë°˜í™˜
                return f"/assets/img/egloos/{img_filename}"
            else:
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ
                print(f"âš ï¸  ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_src}")
                return img_src

        return img_src

    def _html_to_markdown(self, element):
        """HTML ìš”ì†Œë¥¼ Markdownìœ¼ë¡œ ë³€í™˜"""
        result = []
        prev_was_text = False

        for child in element.children:
            if child.name is None:
                # í…ìŠ¤íŠ¸ ë…¸ë“œ
                text = str(child).strip()
                if text:
                    # ì´ì „ì´ divì˜€ê³  í˜„ì¬ê°€ í…ìŠ¤íŠ¸ë©´ ê°œí–‰ ì¶”ê°€
                    if result and not prev_was_text:
                        result.append('\n\n')
                    result.append(text)
                    prev_was_text = True
            elif child.name == 'div':
                # divëŠ” ë‹¨ë½ìœ¼ë¡œ ì²˜ë¦¬ (ë‘ ë²ˆ ê°œí–‰)
                inner = self._html_to_markdown(child)
                if inner.strip():
                    # ì´ì „ì— ë‚´ìš©ì´ ìˆìœ¼ë©´ ê°œí–‰ ì¶”ê°€
                    if result and prev_was_text:
                        result.append('\n\n')
                    result.append(inner.strip() + '\n\n')
                    prev_was_text = False
            elif child.name == 'br':
                result.append('  \n')  # Markdown ì¤„ë°”ê¿ˆ
                prev_was_text = False
            elif child.name == 'img':
                src = child.get('src', '')
                alt = child.get('alt', '')
                result.append(f"\n![{alt}]({src})\n\n")
                prev_was_text = False
            elif child.name in ['p']:
                inner = self._html_to_markdown(child)
                if inner.strip():
                    if result and prev_was_text:
                        result.append('\n\n')
                    result.append(inner.strip() + '\n\n')
                    prev_was_text = False
            else:
                # ê¸°íƒ€ íƒœê·¸ëŠ” ë‚´ë¶€ í…ìŠ¤íŠ¸ë§Œ
                inner = self._html_to_markdown(child)
                if inner.strip():
                    result.append(inner)

        return ''.join(result)

    def _generate_description(self, content):
        """ë³¸ë¬¸ì—ì„œ description ìƒì„± (ì²« 150ì)"""
        # ì¤„ë°”ê¿ˆ, ì´ë¯¸ì§€ ë“± ì œê±°
        clean_content = re.sub(r'!\[.*?\]\(.*?\)', '', content)
        clean_content = re.sub(r'\s+', ' ', clean_content).strip()

        if len(clean_content) > 150:
            return clean_content[:150] + "..."
        return clean_content

    def _extract_first_image(self, soup, html_path):
        """ë³¸ë¬¸ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì¶”ì¶œ (front matterìš©)"""
        content_elem = soup.find('div', class_='post_content entry-content')
        if not content_elem:
            return None

        hentry = content_elem.find('div', class_='hentry')
        if not hentry:
            return None

        img = hentry.find('img')
        if img:
            img_src = img.get('src', '')
            return self._process_image(img_src, html_path)

        return None

    def _extract_comments(self, soup):
        """ëŒ“ê¸€ ì¶”ì¶œ"""
        comments = []
        comment_list = soup.find('ul', class_='comment_list')

        if not comment_list:
            return comments

        for li in comment_list.find_all('li', recursive=False):
            comment = self._parse_comment(li)
            if comment:
                comments.append(comment)

        return comments

    def _parse_comment(self, li_elem):
        """ê°œë³„ ëŒ“ê¸€ íŒŒì‹±"""
        # ì‘ì„±ì
        writer_elem = li_elem.find('span', class_='comment_writer')
        if not writer_elem:
            return None
        writer = writer_elem.get_text().strip()

        # ì‘ì„±ì‹œê°„
        datetime_elem = li_elem.find('span', class_='comment_datetime')
        datetime_str = datetime_elem.get('title', '') if datetime_elem else ''

        # ëŒ“ê¸€ ë‚´ìš©
        # comment_id ì°¾ê¸°
        comment_id = None
        for div in li_elem.find_all('div'):
            div_id = div.get('id', '')
            if div_id.startswith('comment_'):
                comment_id = div_id
                break

        content = ''
        if comment_id:
            content_elem = li_elem.find('div', id=comment_id)
            if content_elem:
                # br íƒœê·¸ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ
                for br in content_elem.find_all('br'):
                    br.replace_with('\n')
                content = content_elem.get_text().strip()

        # ëŒ€ëŒ“ê¸€ ì—¬ë¶€
        is_reply = 'comment_reply' in li_elem.get('class', [])

        return {
            'writer': writer,
            'datetime': datetime_str,
            'content': content,
            'is_reply': is_reply
        }

    def _generate_markdown(self, title, date, categories, description,
                          first_image, content, comments):
        """Markdown ë¬¸ì„œ ìƒì„±"""
        lines = []

        # Front matter
        lines.append('---')
        lines.append(f'title: "{title}"')
        lines.append(f'categories: {categories}')
        lines.append('comments: true')
        lines.append(f'description: "{description}"')
        if first_image:
            lines.append(f'image: "{first_image}"')
        lines.append(f'date: {date.strftime("%Y-%m-%d %H:%M")}')
        lines.append('---')
        lines.append('')

        # ë³¸ë¬¸
        lines.append(content)
        lines.append('')

        # ëŒ“ê¸€
        if comments:
            lines.append('---')
            lines.append('')
            lines.append('## ëŒ“ê¸€')
            lines.append('')

            for comment in comments:
                # ì¼ë°˜ ëŒ“ê¸€: '> ', ëŒ€ëŒ“ê¸€: '>> '
                indent = '>> ' if comment['is_reply'] else '> '
                lines.append(f"{indent}**{comment['writer']}** Â· _{comment['datetime']}_")
                lines.append(f"{indent}")

                # ëŒ“ê¸€ ë‚´ìš© (ê° ì¤„ë§ˆë‹¤ indent ì¶”ê°€)
                content_lines = comment['content'].split('\n')
                for line in content_lines:
                    lines.append(f"{indent}{line}")
                lines.append('')

        return '\n'.join(lines)

    def _generate_filename(self, date, title):
        """íŒŒì¼ëª… ìƒì„±: {Year}-{Month}-{Day}-{Title}.md"""
        # ë‚ ì§œ ë¶€ë¶„
        date_str = date.strftime('%Y-%m-%d')

        # ì œëª©ì„ íŒŒì¼ëª…ìœ¼ë¡œ (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        safe_title = re.sub(r'[^\w\sê°€-í£-]', '', title)
        safe_title = re.sub(r'\s+', '-', safe_title)

        return f"{date_str}-{safe_title}.md"

    def convert_all(self, start_file='3014219.html', end_file='4799567.html'):
        """ëª¨ë“  HTML íŒŒì¼ ë³€í™˜"""
        html_dir = self.base_dir / 'calmglow.egloos.com'

        if not html_dir.exists():
            print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {html_dir}")
            return

        # HTML íŒŒì¼ ëª©ë¡
        html_files = sorted(html_dir.glob('*.html'))

        # íŒŒì¼ëª…ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ì—¬ ë²”ìœ„ í•„í„°ë§
        start_num = int(re.search(r'\d+', start_file).group())
        end_num = int(re.search(r'\d+', end_file).group())

        filtered_files = []
        for f in html_files:
            match = re.search(r'(\d+)\.html$', f.name)
            if match:
                num = int(match.group(1))
                if start_num <= num <= end_num:
                    filtered_files.append(f)

        print(f"ğŸ“ ì´ {len(filtered_files)}ê°œ íŒŒì¼ ë³€í™˜ ì‹œì‘...")

        success_count = 0
        for html_file in filtered_files:
            print(f"ğŸ”„ ë³€í™˜ ì¤‘: {html_file.name}")
            result = self.convert_file(html_file)
            if result:
                success_count += 1
                print(f"âœ… ì™„ë£Œ: {result.name}")

        print(f"\n{'='*50}")
        print(f"âœ… ì„±ê³µ: {success_count}/{len(filtered_files)}")
        print(f"âŒ ì‹¤íŒ¨: {len(self.error_log)}")

        if self.error_log:
            print(f"\nì—ëŸ¬ ë¡œê·¸:")
            for error in self.error_log:
                print(f"  - {error}")


def main():
    # ê²½ë¡œ ì„¤ì •
    base_dir = Path.home() / 'blog' / 'egloos'
    output_dir = base_dir / 'migration'
    assets_dir = base_dir / 'assets' / 'img' / 'egloos'

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)

    # ë³€í™˜ê¸° ìƒì„±
    converter = EgloosConverter(base_dir, output_dir, assets_dir)

    # ì „ì²´ ë³€í™˜ ì‹¤í–‰
    print("ğŸš€ ì „ì²´ HTML íŒŒì¼ ë³€í™˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ğŸ“‚ ì…ë ¥: {base_dir / 'calmglow.egloos.com'}")
    print(f"ğŸ“‚ ì¶œë ¥: {output_dir}")
    print(f"ğŸ–¼ï¸  ì´ë¯¸ì§€: {assets_dir}")
    print("")

    converter.convert_all()


if __name__ == '__main__':
    main()
